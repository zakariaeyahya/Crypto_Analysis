# Fine-tuning de RoBERTa pour l'Analyse de Sentiment des Tweets Crypto

Ce projet impl√©mente le fine-tuning du mod√®le RoBERTa pour classifier le sentiment des tweets Bitcoin en utilisant un dataset de 19+ millions de tweets.

## üìã Table des mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Structure du projet](#structure-du-projet)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [R√©sultats](#r√©sultats)
- [Documentation](#documentation)

## üéØ Vue d'ensemble

Le projet fine-tune le mod√®le **RoBERTa** (sp√©cifiquement `cardiffnlp/twitter-roberta-base-sentiment`) pour classifier le sentiment des tweets crypto en trois cat√©gories :
- **POSITIF** : Sentiment positif
- **NEGATIF** : Sentiment n√©gatif  
- **NEUTRE** : Sentiment neutre

### Caract√©ristiques principales

- ‚úÖ Support CUDA/GPU pour l'entra√Ænement acc√©l√©r√©
- ‚úÖ Mixed precision training (FP16) pour optimiser la m√©moire
- ‚úÖ Gestion de datasets volumineux (chargement par chunks)
- ‚úÖ Early stopping pour √©viter l'overfitting
- ‚úÖ Checkpoints automatiques
- ‚úÖ Visualisations compl√®tes des r√©sultats
- ‚úÖ Script d'inf√©rence pour nouvelles pr√©dictions

### üìì Format du code

Ce projet est disponible sous **deux formats √©quivalents** :

1. **Fichiers Python (.py)** : Code modulaire organis√© en scripts s√©par√©s
   - `data_preparation.py`, `preprocessing.py`, `train.py`, `evaluate.py`, etc.
   - Id√©al pour l'ex√©cution en ligne de commande et l'int√©gration dans des pipelines

2. **Notebook Jupyter (.ipynb)** : `roberta-1-1.ipynb`
   - Contient **exactement le m√™me code** que les fichiers .py
   - Organis√© en cellules pour une exploration interactive
   - Id√©al pour le d√©veloppement, le d√©bogage et la visualisation √©tape par √©tape

**Note importante** : Le notebook `roberta-1-1.ipynb` et les fichiers `.py` impl√©mentent la m√™me logique et produisent les m√™mes r√©sultats. Les r√©sultats d'entra√Ænement g√©n√©r√©s par le notebook sont disponibles dans le dossier `output/`. Pour une interpr√©tation d√©taill√©e des r√©sultats, consultez `output/results/README_INTERPRETATION.md`.

## üìÅ Structure du projet

```
Finetuning/
‚îú‚îÄ‚îÄ config.yaml              # Configuration globale
‚îú‚îÄ‚îÄ data_preparation.py      # Chargement et analyse des donn√©es
‚îú‚îÄ‚îÄ preprocessing.py         # Nettoyage et pr√©processing des textes
‚îú‚îÄ‚îÄ model_config.py          # Configuration du mod√®le RoBERTa
‚îú‚îÄ‚îÄ train.py                 # Script d'entra√Ænement principal
‚îú‚îÄ‚îÄ evaluate.py              # √âvaluation du mod√®le
‚îú‚îÄ‚îÄ inference.py             # Pr√©dictions sur nouveaux tweets
‚îú‚îÄ‚îÄ visualize.py             # Visualisations des r√©sultats
‚îú‚îÄ‚îÄ utils.py                 # Fonctions utilitaires
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                # Documentation
‚îú‚îÄ‚îÄ roberta-1-1.ipynb        # Notebook Jupyter (m√™me code que les .py)
‚îú‚îÄ‚îÄ roberta_finetuning_prompt.txt  # Prompt original du projet
‚îú‚îÄ‚îÄ models/                  # Mod√®les sauvegard√©s
‚îú‚îÄ‚îÄ logs/                    # Logs d'entra√Ænement
‚îú‚îÄ‚îÄ checkpoints/             # Checkpoints interm√©diaires
‚îú‚îÄ‚îÄ results/                 # R√©sultats et visualisations
‚îî‚îÄ‚îÄ output/                  # R√©sultats g√©n√©r√©s par le notebook
    ‚îú‚îÄ‚îÄ models/              # Mod√®les entra√Æn√©s
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model/      # Meilleur mod√®le
    ‚îÇ   ‚îú‚îÄ‚îÄ final_model/     # Mod√®le final
    ‚îÇ   ‚îî‚îÄ‚îÄ label_mapping.json
    ‚îî‚îÄ‚îÄ results/              # M√©triques et visualisations
        ‚îú‚îÄ‚îÄ training_metrics.json
        ‚îú‚îÄ‚îÄ training_curves.png
        ‚îú‚îÄ‚îÄ confusion_matrix.png
        ‚îú‚îÄ‚îÄ train_split.csv
        ‚îú‚îÄ‚îÄ val_split.csv
        ‚îú‚îÄ‚îÄ test_split.csv
        ‚îî‚îÄ‚îÄ README_INTERPRETATION.md  # Interpr√©tation d√©taill√©e des r√©sultats
```

## üöÄ Installation

### Pr√©requis

- Python 3.8+
- CUDA-capable GPU (recommand√©, 8GB+ VRAM)
- 10GB+ d'espace disque pour le dataset

### Installation des d√©pendances

```bash
pip install -r Finetuning/requirements.txt
```

### Installation de PyTorch avec CUDA

Pour utiliser le GPU, installez PyTorch avec support CUDA :

```bash
# Pour CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Pour CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

V√©rifiez que CUDA est disponible :

```python
import torch
print(torch.cuda.is_available())  # Doit retourner True
print(torch.cuda.get_device_name(0))  # Nom du GPU
```

## ‚öôÔ∏è Configuration

Le fichier `config.yaml` contient toute la configuration du projet. Principales sections :

### Mod√®le
- `model.name` : Mod√®le Hugging Face √† utiliser
- `model.num_labels` : Nombre de classes (3 pour sentiment)
- `model.max_length` : Longueur maximale des s√©quences (128 tokens)

### Donn√©es
- `data.csv_path` : Chemin vers le dataset CSV
- `data.sample_size` : Nombre de tweets √† utiliser (None = tout)
- `data.train_split`, `data.val_split`, `data.test_split` : Proportions des splits

### Entra√Ænement
- `training.batch_size` : Taille des batches (32 par d√©faut)
- `training.learning_rate` : Taux d'apprentissage (2e-5 par d√©faut)
- `training.num_epochs` : Nombre d'epochs (5 par d√©faut)
- `training.use_fp16` : Mixed precision training (True par d√©faut)
- `training.use_cuda` : Utiliser CUDA si disponible (True par d√©faut)

## üìñ Utilisation

### 1. Pr√©paration des donn√©es

Le dataset doit √™tre dans `data/bronze/kaggle/bitcoin_tweets_YYYYMMDD_HHMMSS.csv` avec les colonnes :
- `Date` : Date du tweet
- `text` : Texte du tweet
- `Sentiment` : Label (POSITIF/NEGATIF/NEUTRE)

### 2. Entra√Ænement

Lancer l'entra√Ænement :

```bash
python Finetuning/train.py
```

Le script va :
1. Charger et analyser les donn√©es
2. Pr√©processer les textes
3. Diviser en train/val/test
4. Entra√Æner le mod√®le avec CUDA
5. Sauvegarder les checkpoints et le mod√®le final

### 3. √âvaluation

√âvaluer le mod√®le sur le test set :

```bash
python Finetuning/evaluate.py
```

Cela g√©n√®re :
- M√©triques d√©taill√©es (accuracy, F1, precision, recall)
- Matrice de confusion
- Classification report
- Fichier JSON avec tous les r√©sultats

### 4. Visualisations

Cr√©er les visualisations :

```bash
python Finetuning/visualize.py
```

G√©n√®re :
- Courbes d'entra√Ænement (loss, accuracy, F1)
- Matrice de confusion
- Comparaison des m√©triques par classe

### 5. Inf√©rence

Pr√©dire le sentiment de nouveaux tweets :

```python
from Finetuning.inference import SentimentPredictor

# Charger le mod√®le
predictor = SentimentPredictor(
    model_path="Finetuning/models/roberta-bitcoin-sentiment",
    use_cuda=True
)

# Pr√©diction simple
sentiment = predictor.predict("Bitcoin is going to the moon! üöÄ")
print(sentiment)  # "POSITIF"

# Pr√©diction avec probabilit√©s
result = predictor.predict("Bitcoin is going to the moon! üöÄ", return_proba=True)
print(result)
# {
#     "label": "POSITIF",
#     "probabilities": {"POSITIF": 0.85, "NEUTRE": 0.10, "NEGATIF": 0.05},
#     "confidence": 0.85
# }

# Pr√©diction par batch
tweets = ["Tweet 1", "Tweet 2", "Tweet 3"]
predictions = predictor.predict_batch(tweets, batch_size=32)
```

## üìä R√©sultats

### M√©triques cibles

- Accuracy > 75%
- F1-Score macro > 0.70
- F1-Score par classe > 0.65
- Temps d'inf√©rence < 100ms par tweet

### R√©sultats d'entra√Ænement

Les r√©sultats de l'entra√Ænement effectu√© via le notebook `roberta-1-1.ipynb` sont disponibles dans `Finetuning/output/` :

**M√©triques obtenues** :
- **Accuracy (validation)** : 70.1%
- **F1-Score macro (validation)** : 0.686 (68.6%)
- **Meilleur F1-Score** : 0.686 (epoch 8)
- **Temps d'entra√Ænement** : ~8.8 heures (8 epochs)

Pour une **interpr√©tation d√©taill√©e** des r√©sultats, consultez :
- üìÑ `output/results/README_INTERPRETATION.md` : Analyse compl√®te des performances, √©volution des m√©triques, recommandations d'am√©lioration

### Fichiers g√©n√©r√©s

Apr√®s l'entra√Ænement, vous trouverez dans `Finetuning/results/` (ou `Finetuning/output/results/` pour le notebook) :

- `training_metrics.json` : M√©triques d'entra√Ænement
- `evaluation_results.json` : R√©sultats d'√©valuation
- `training_curves.png` : Courbes d'entra√Ænement
- `confusion_matrix.png` : Matrice de confusion
- `metrics_comparison.png` : Comparaison des m√©triques

Dans `Finetuning/models/` (ou `Finetuning/output/models/` pour le notebook) :

- `best_model/` : Meilleur mod√®le bas√© sur validation F1-score
- `final_model/` : Mod√®le final apr√®s tous les epochs
- `label_mapping.json` : Mapping des labels

Dans `Finetuning/checkpoints/` :

- `checkpoint_epoch_N.pt` : Checkpoints par epoch
- `best_model.pt` : Meilleur mod√®le (bas√© sur F1 validation)

## üîß Optimisations

### Pour GPU avec m√©moire limit√©e

1. R√©duire `batch_size` (16 ou 8)
2. Activer `gradient_accumulation_steps` (2 ou 4)
3. Utiliser `use_fp16: true` pour mixed precision
4. R√©duire `max_length` (64 ou 96 au lieu de 128)

### Pour datasets tr√®s volumineux

1. Utiliser `sample_size` pour √©chantillonner
2. Augmenter `chunk_size` pour le chargement
3. Utiliser data streaming (√† impl√©menter)

## üêõ D√©pannage

### CUDA non disponible

Si `torch.cuda.is_available()` retourne `False` :

1. V√©rifier l'installation de PyTorch avec CUDA
2. V√©rifier que les drivers NVIDIA sont √† jour
3. Le code basculera automatiquement sur CPU

### Erreur de m√©moire GPU

1. R√©duire `batch_size`
2. Activer `use_fp16: true`
3. R√©duire `sample_size` pour utiliser moins de donn√©es

### Dataset trop volumineux

1. Utiliser `sample_size` dans la config (ex: 1000000)
2. Augmenter `chunk_size` pour le chargement

## üìö Documentation

- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [RoBERTa Paper](https://arxiv.org/abs/1907.11692)
- [PyTorch Documentation](https://pytorch.org/docs/)

## üìù Notes

- Le dataset complet fait ~3GB avec 19M tweets
- L'entra√Ænement sur le dataset complet peut prendre plusieurs heures/jours
- Commencer avec un √©chantillon (100k-1M tweets) pour tester
- Le mod√®le utilise `cardiffnlp/twitter-roberta-base-sentiment` qui est pr√©-entra√Æn√© sur Twitter

## ü§ù Contribution

Pour am√©liorer le projet :
1. Tester diff√©rents hyperparam√®tres
2. Essayer d'autres mod√®les pr√©-entra√Æn√©s
3. Impl√©menter data augmentation
4. Ajouter cross-validation

## üìÑ Licence

Ce projet fait partie du projet Crypto_Analysis.





