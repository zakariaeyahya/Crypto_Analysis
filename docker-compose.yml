services:
  # ==========================================================================
  # ==========================================================================
  postgres:
    networks:
      - airflow-network
    image: postgres:13
    container_name: crypto_airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  # ==========================================================================
  # Airflow Init - Initialize database (run once)
  # ==========================================================================
  airflow-init:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: crypto_airflow_init
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username airflow --firstname Admin --lastname User --role Admin --email admin@example.com --password airflow"
    env_file:
      - .env.airflow
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - airflow-network

  # ==========================================================================
  # Airflow Webserver - Interface web sur http://localhost:8080
  # ==========================================================================
  airflow-webserver:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: crypto_airflow_webserver
    command: webserver
    ports:
      - "8080:8080"
    env_file:
      - .env.airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./data_consolidation:/opt/airflow/data_consolidation
      - ./EDA_Task:/opt/airflow/EDA_Task
      - ./extraction:/opt/airflow/extraction
      - ./data_cleaning:/opt/airflow/data_cleaning
      - ./Finetuning:/opt/airflow/Finetuning
      - ./.env:/opt/airflow/.env
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - airflow-network
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always

  # ==========================================================================
  # Airflow Scheduler - Ordonnanceur des DAGs
  # ==========================================================================
  airflow-scheduler:
    build:
      context: .
      dockerfile: docker/Dockerfile.airflow
    container_name: crypto_airflow_scheduler
    command: scheduler
    env_file:
      - .env.airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./data_consolidation:/opt/airflow/data_consolidation
      - ./EDA_Task:/opt/airflow/EDA_Task
      - ./extraction:/opt/airflow/extraction
      - ./data_cleaning:/opt/airflow/data_cleaning
      - ./Finetuning:/opt/airflow/Finetuning
      - ./.env:/opt/airflow/.env
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - airflow-network
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob", "--hostname", "$${HOSTNAME}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always

# ============================================================================
# ============================================================================
networks:
  airflow-network:
    driver: bridge

volumes:
  postgres-db-volume:
    name: crypto_airflow_postgres_data
