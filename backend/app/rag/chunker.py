"""
D√©coupe les documents longs en morceaux plus petits (chunks) pour une meilleure
pr√©cision de recherche.
"""

import re
import copy
from app.rag.logger import get_logger

logger = get_logger("chunker")


class DocumentChunker:
    """D√©coupe les documents en chunks optimis√©s pour la recherche"""

    def __init__(self, chunk_size=500, overlap=50):
        """
        Initialise le chunker
        
        Args:
            chunk_size (int): Taille maximale d'un chunk en caract√®res (d√©faut: 500)
            overlap (int): Chevauchement entre chunks en mots (d√©faut: 50)
        """
        self.chunk_size = chunk_size
        self.overlap = overlap
        logger.info(f"DocumentChunker initialis√©: chunk_size={chunk_size}, overlap={overlap}")

    def _split_into_sentences(self, text):
        """
        D√©coupe le texte en phrases
        
        Args:
            text (str): Texte √† d√©couper
            
        Returns:
            list: Liste des phrases
        """
        # Pattern pour d√©couper apr√®s . ! ? suivi d'un espace
        pattern = r'(?<=[.!?])\s+'
        sentences = re.split(pattern, text)
        # Filtrer les phrases vides
        sentences = [s.strip() for s in sentences if s.strip()]
        return sentences

    def chunk_document(self, doc):
        """
        D√©coupe un document en chunks
        
        Args:
            doc (dict): Document √† d√©couper
            
        Returns:
            list: Liste des chunks du document
        """
        text = doc.get("text", "")
        
        # Si texte court, pas de d√©coupage n√©cessaire
        if len(text) <= self.chunk_size:
            chunk = copy.deepcopy(doc)
            chunk["id"] = f"{doc['id']}_0"
            logger.debug(f"Document court: {doc['id']} ({len(text)} caract√®res)")
            return [chunk]
        
        # Sinon, d√©couper en phrases puis regrouper
        sentences = self._split_into_sentences(text)
        chunks = []
        current_chunk = ""
        chunk_index = 0

        for sentence in sentences:
            # Si ajouter la phrase d√©passe la taille max
            if len(current_chunk) + len(sentence) + 1 > self.chunk_size:
                # Sauvegarder le chunk actuel s'il n'est pas vide
                if current_chunk.strip():
                    chunk = copy.deepcopy(doc)
                    chunk["id"] = f"{doc['id']}_{chunk_index}"
                    chunk["text"] = current_chunk.strip()
                    chunk["chunk_index"] = chunk_index
                    chunks.append(chunk)
                    logger.debug(f"Chunk cr√©√©: {chunk['id']} ({len(current_chunk)} caract√®res)")
                    chunk_index += 1

                # Nouveau chunk avec overlap (derniers mots du chunk pr√©c√©dent)
                words = current_chunk.split()
                overlap_text = " ".join(words[-10:]) if len(words) > 10 else current_chunk
                current_chunk = overlap_text + " " + sentence
            else:
                # Ajouter la phrase au chunk courant
                current_chunk += " " + sentence if current_chunk else sentence

        # Sauvegarder le dernier chunk
        if current_chunk.strip():
            chunk = copy.deepcopy(doc)
            chunk["id"] = f"{doc['id']}_{chunk_index}"
            chunk["text"] = current_chunk.strip()
            chunk["chunk_index"] = chunk_index
            chunks.append(chunk)
            logger.debug(f"Chunk cr√©√© (dernier): {chunk['id']} ({len(current_chunk)} caract√®res)")

        logger.info(f"Document {doc['id']} d√©coup√© en {len(chunks)} chunks")
        return chunks

    def chunk_all(self, documents):
        """
        D√©coupe tous les documents
        
        Args:
            documents (list): Liste des documents √† d√©couper
            
        Returns:
            list: Liste de tous les chunks
        """
        all_chunks = []
        
        for doc in documents:
            chunks = self.chunk_document(doc)
            all_chunks.extend(chunks)
        
        logger.info(f"‚úì Cr√©√© {len(all_chunks)} chunks √† partir de {len(documents)} documents")
        return all_chunks

    def get_stats(self, chunks):
        """
        Retourne les statistiques des chunks
        
        Args:
            chunks (list): Liste des chunks
            
        Returns:
            dict: Statistiques (total, longueur moyenne, par type)
        """
        if not chunks:
            logger.warning("Aucun chunk √† analyser")
            return {
                "total_chunks": 0,
                "avg_length": 0,
                "by_type": {}
            }

        total = len(chunks)
        lengths = [len(c.get("text", "")) for c in chunks]
        avg_length = sum(lengths) / total if total > 0 else 0
        min_length = min(lengths) if lengths else 0
        max_length = max(lengths) if lengths else 0

        # Compter par type de document
        by_type = {}
        for chunk in chunks:
            doc_type = chunk.get("type", "unknown")
            by_type[doc_type] = by_type.get(doc_type, 0) + 1

        stats = {
            "total_chunks": total,
            "avg_length": round(avg_length, 2),
            "min_length": min_length,
            "max_length": max_length,
            "by_type": by_type,
        }

        logger.info(f"Statistiques chunks: {stats}")
        return stats

    def display_stats(self, chunks):
        """
        Affiche les statistiques de mani√®re lisible
        
        Args:
            chunks (list): Liste des chunks
        """
        stats = self.get_stats(chunks)
        
        print("\n" + "="*60)
        print("üìä STATISTIQUES DES CHUNKS")
        print("="*60)
        print(f"Total chunks:        {stats['total_chunks']}")
        print(f"Longueur moyenne:    {stats['avg_length']:.0f} caract√®res")
        print(f"Longueur min:        {stats['min_length']} caract√®res")
        print(f"Longueur max:        {stats['max_length']} caract√®res")
        print("\nPar type de document:")
        for doc_type, count in stats['by_type'].items():
            print(f"  - {doc_type}: {count} chunks")
        print("="*60 + "\n")